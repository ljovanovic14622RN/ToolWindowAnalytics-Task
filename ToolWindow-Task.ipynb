{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "757c3ee9-376b-4a73-b9f0-393291f03776",
      "cell_type": "code",
      "source": "import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.backends.backend_pdf import PdfPages\n\nDATA_PATH = \"toolwindow_data.csv\"\nOUT_DIR = \".\"\n\ndef load_and_clean(path):\n    df = pd.read_csv(path)\n    df.columns = [c.strip().lower() for c in df.columns]\n    df[\"event\"] = df[\"event\"].str.strip().str.lower().map({\"opened\":\"open\",\"closed\":\"close\"})\n    df = df.rename(columns={\"event\":\"event_id\"})\n    df[\"timestamp\"] = pd.to_numeric(df[\"timestamp\"], errors=\"coerce\").astype(\"Int64\")\n    df = df.dropna(subset=[\"timestamp\"]).copy()\n    df[\"timestamp\"] = df[\"timestamp\"].astype(\"int64\")\n    df[\"open_type\"] = df[\"open_type\"].astype(str).str.strip().str.lower()\n    df.loc[~df[\"open_type\"].isin([\"manual\",\"auto\"]), \"open_type\"] = None\n    df = df.sort_values([\"user_id\",\"timestamp\"]).reset_index(drop=True)\n    is_open = df[\"event_id\"].eq(\"open\")\n    is_close = df[\"event_id\"].eq(\"close\")\n    df_clean = df.loc[is_close | (is_open & df[\"open_type\"].isin([\"manual\",\"auto\"]))].copy()\n    return df_clean\n\ndef build_episodes(df_clean, mode=\"implicit\"):\n    episodes = []\n    orphan_closes = 0\n    implicit_closes = 0\n    skipped_double_opens = 0\n    right_censored = 0\n    for uid, g in df_clean.groupby(\"user_id\", sort=False):\n        current_open = None\n        for _, row in g.iterrows():\n            if row[\"event_id\"] == \"open\":\n                if current_open is not None:\n                    if mode == \"implicit\":\n                        episodes.append({\"user_id\": uid, \"open_ts\": current_open[\"timestamp\"], \"close_ts\": row[\"timestamp\"], \"open_type\": current_open[\"open_type\"], \"implicit_closed\": True})\n                        implicit_closes += 1\n                        current_open = {\"timestamp\": row[\"timestamp\"], \"open_type\": row[\"open_type\"]}\n                    elif mode == \"skip\":\n                        skipped_double_opens += 1\n                        continue\n                else:\n                    current_open = {\"timestamp\": row[\"timestamp\"], \"open_type\": row[\"open_type\"]}\n            else:\n                if current_open is None:\n                    orphan_closes += 1\n                else:\n                    episodes.append({\"user_id\": uid, \"open_ts\": current_open[\"timestamp\"], \"close_ts\": row[\"timestamp\"], \"open_type\": current_open[\"open_type\"], \"implicit_closed\": False})\n                    current_open = None\n        if current_open is not None:\n            right_censored += 1\n            if mode == \"implicit\":\n                episodes.append({\"user_id\": uid, \"open_ts\": current_open[\"timestamp\"], \"close_ts\": np.nan, \"open_type\": current_open[\"open_type\"], \"implicit_closed\": False, \"censored\": True})\n    ep = pd.DataFrame(episodes)\n    if ep.empty:\n        complete = pd.DataFrame(columns=[\"user_id\",\"open_ts\",\"close_ts\",\"open_type\",\"duration_s\"])\n    else:\n        if \"censored\" in ep.columns:\n            ep[\"censored\"] = ep[\"censored\"].fillna(False)\n            ep = ep.loc[~ep[\"censored\"] & ep[\"close_ts\"].notna()].copy()\n        complete = ep.copy()\n        complete[\"duration_s\"] = (complete[\"close_ts\"] - complete[\"open_ts\"]) / 1000.0\n        complete = complete.loc[complete[\"duration_s\"] > 0].copy()\n    meta = {\"orphan_closes\": orphan_closes, \"implicit_closes\": implicit_closes, \"skipped_double_opens\": skipped_double_opens, \"right_censored\": right_censored}\n    return complete, meta\n\ndef stats_by_type(complete):\n    out = []\n    for ot in [\"manual\",\"auto\"]:\n        vals = complete.loc[complete[\"open_type\"]==ot,\"duration_s\"].to_numpy()\n        if len(vals)==0:\n            out.append({\"open_type\": ot, \"n\": 0, \"mean_s\": np.nan, \"median_s\": np.nan, \"p75_s\": np.nan, \"p95_s\": np.nan, \"p99_s\": np.nan, \"max_s\": np.nan})\n        else:\n            out.append({\"open_type\": ot, \"n\": int(len(vals)), \"mean_s\": float(vals.mean()), \"median_s\": float(np.median(vals)), \"p75_s\": float(np.percentile(vals,75)), \"p95_s\": float(np.percentile(vals,95)), \"p99_s\": float(np.percentile(vals,99)), \"max_s\": float(vals.max())})\n    return pd.DataFrame(out)\n\ndef winsorize(arr, p_lo=1, p_hi=99):\n    if len(arr)==0:\n        return arr\n    lo = np.percentile(arr, p_lo)\n    hi = np.percentile(arr, p_hi)\n    return np.clip(arr, lo, hi)\n\ndef winsor_stats(complete, p_lo=1, p_hi=99):\n    out = []\n    for ot in [\"manual\",\"auto\"]:\n        vals = complete.loc[complete[\"open_type\"]==ot,\"duration_s\"].to_numpy()\n        if len(vals)==0:\n            out.append({\"open_type\": ot, \"winsor_mean_p1_p99_s\": np.nan})\n        else:\n            w = winsorize(vals, p_lo=p_lo, p_hi=p_hi)\n            out.append({\"open_type\": ot, \"winsor_mean_p1_p99_s\": float(w.mean())})\n    return pd.DataFrame(out)\n\ndef permutation_mean_diff(manual, auto, seed=123, perms=3000):\n    if len(manual)==0 or len(auto)==0:\n        return np.nan, np.nan\n    rng = np.random.default_rng(seed)\n    combined = np.concatenate([manual, auto])\n    n_m = len(manual)\n    obs = manual.mean() - auto.mean()\n    extreme = 0\n    for _ in range(perms):\n        rng.shuffle(combined)\n        m = combined[:n_m]\n        a = combined[n_m:]\n        diff = m.mean() - a.mean()\n        if abs(diff) >= abs(obs):\n            extreme += 1\n    p_val = (extreme + 1) / (perms + 1)\n    return p_val, obs\n\ndef ecdf(x):\n    x = np.sort(x)\n    y = np.arange(1, len(x)+1) / len(x)\n    return x, y\n\ndf_clean = load_and_clean(DATA_PATH)\nimplicit_eps, implicit_meta = build_episodes(df_clean, mode=\"implicit\")\nskip_eps, skip_meta = build_episodes(df_clean, mode=\"skip\")\nimplicit_eps.to_csv(os.path.join(OUT_DIR, \"episodes_implicit.csv\"), index=False)\nskip_eps.to_csv(os.path.join(OUT_DIR, \"episodes_skip.csv\"), index=False)\n\nimp_stats = stats_by_type(implicit_eps)\nskp_stats = stats_by_type(skip_eps)\nimp_w = winsor_stats(implicit_eps)\nskp_w = winsor_stats(skip_eps)\n\nimp_manual = implicit_eps.loc[implicit_eps[\"open_type\"]==\"manual\",\"duration_s\"].to_numpy()\nimp_auto   = implicit_eps.loc[implicit_eps[\"open_type\"]==\"auto\",\"duration_s\"].to_numpy()\nskp_manual = skip_eps.loc[skip_eps[\"open_type\"]==\"manual\",\"duration_s\"].to_numpy()\nskp_auto   = skip_eps.loc[skip_eps[\"open_type\"]==\"auto\",\"duration_s\"].to_numpy()\np_imp, diff_imp = permutation_mean_diff(imp_manual, imp_auto, seed=42, perms=3000)\np_skp, diff_skp = permutation_mean_diff(skp_manual, skp_auto, seed=7, perms=3000)\n\npdf_path = os.path.join(OUT_DIR, \"toolwindow_analysis_comparison_with_winsor.pdf\")\nwith PdfPages(pdf_path) as pdf:\n    fig = plt.figure(figsize=(8.27, 11.69))\n    lines = []\n    lines.append(\"Analyze Toolwindow Usage Data — Two strategies + Winsorizing\")\n    lines.append(\"\")\n    lines.append(\"Cleaning: keep CLOSE; keep OPEN only with open_type ∈ {manual, auto}; sort by user_id,timestamp.\")\n    lines.append(\"A) implicit_close: second OPEN closes current episode at its time, then new episode starts; censored excluded.\")\n    lines.append(\"B) skip_double_open: second OPEN while open is ignored; censored excluded.\")\n    lines.append(\"Orphan CLOSE ignored; non-positive durations dropped.\")\n    lines.append(\"\")\n    lines.append(f\"A) meta: {implicit_meta}\")\n    lines.append(f\"B) meta: {skip_meta}\")\n    plt.axis(\"off\")\n    plt.text(0.05, 0.98, \"\\n\".join(lines), va=\"top\", ha=\"left\", fontsize=10, family=\"monospace\")\n    pdf.savefig(fig, bbox_inches=\"tight\")\n    plt.close(fig)\n\n    for title, stats_df, wins_df in [(\"implicit_close\", imp_stats, imp_w), (\"skip_double_open\", skp_stats, skp_w)]:\n        fig = plt.figure(figsize=(8.27, 6))\n        merged = stats_df.merge(wins_df, on=\"open_type\", how=\"left\")\n        txt = [f\"{title} — per open_type\"]\n        for _, r in merged.iterrows():\n            txt.append(f\"{r['open_type']}: n={int(r['n'])}, median={r['median_s']:.2f}s, mean={r['mean_s']:.2f}s, p75={r['p75_s']:.2f}s, p95={r['p95_s']:.2f}s, p99={r['p99_s']:.2f}s, max={r['max_s']:.2f}s, winsor_mean(p1–p99)={r['winsor_mean_p1_p99_s']:.2f}s\")\n        plt.axis(\"off\")\n        plt.text(0.02, 0.98, \"\\n\".join(txt), va=\"top\", ha=\"left\", fontsize=10, family=\"monospace\")\n        pdf.savefig(fig, bbox_inches=\"tight\")\n        plt.close(fig)\n\n    for vname, eps in [(\"implicit_close\", implicit_eps), (\"skip_double_open\", skip_eps)]:\n        counts = eps[\"open_type\"].value_counts().reindex([\"manual\",\"auto\"]).fillna(0).astype(int)\n        plt.figure()\n        plt.bar(counts.index.astype(str), counts.values)\n        plt.title(f\"Episodes count by open_type — {vname}\")\n        plt.ylabel(\"count\")\n        pdf.savefig(bbox_inches=\"tight\")\n        plt.close()\n\n    for vname, eps in [(\"implicit_close\", implicit_eps), (\"skip_double_open\", skip_eps)]:\n        manual = eps.loc[eps[\"open_type\"]==\"manual\",\"duration_s\"].to_numpy()\n        auto   = eps.loc[eps[\"open_type\"]==\"auto\",\"duration_s\"].to_numpy()\n        labels, data = [], []\n        if len(manual)>0: labels.append(\"manual\"); data.append(manual)\n        if len(auto)>0: labels.append(\"auto\"); data.append(auto)\n        if data:\n            plt.figure()\n            plt.boxplot(data, labels=labels, showmeans=True)\n            plt.title(f\"Duration (s) — boxplot — {vname}\")\n            plt.ylabel(\"seconds\")\n            pdf.savefig(bbox_inches=\"tight\")\n            plt.close()\n\n    for vname, eps in [(\"implicit_close\", implicit_eps), (\"skip_double_open\", skip_eps)]:\n        manual = eps.loc[eps[\"open_type\"]==\"manual\",\"duration_s\"].to_numpy()\n        auto   = eps.loc[eps[\"open_type\"]==\"auto\",\"duration_s\"].to_numpy()\n        plt.figure()\n        plotted = False\n        if len(manual)>0:\n            xm = np.sort(manual); ym = np.arange(1, len(manual)+1)/len(manual)\n            plt.step(xm, ym, where=\"post\", label=\"manual\")\n            plotted = True\n        if len(auto)>0:\n            xa = np.sort(auto); ya = np.arange(1, len(auto)+1)/len(auto)\n            plt.step(xa, ya, where=\"post\", label=\"auto\")\n            plotted = True\n        if plotted:\n            plt.title(f\"ECDF — {vname}\")\n            plt.xlabel(\"duration (s)\")\n            plt.ylabel(\"ECDF\")\n            plt.legend()\n            pdf.savefig(bbox_inches=\"tight\")\n            plt.close()\n\n    for vname, eps, wins in [(\"implicit_close\", implicit_eps, imp_w), (\"skip_double_open\", skip_eps, skp_w)]:\n        means = eps.groupby(\"open_type\")[\"duration_s\"].mean().reindex([\"manual\",\"auto\"])\n        wmeans = wins.set_index(\"open_type\")[\"winsor_mean_p1_p99_s\"].reindex([\"manual\",\"auto\"])\n        X = np.arange(2); width = 0.35\n        plt.figure()\n        plt.bar(X - width/2, means.values, width, label=\"mean\")\n        plt.bar(X + width/2, wmeans.values, width, label=\"winsor_mean p1–p99\")\n        plt.xticks(X, [\"manual\",\"auto\"])\n        plt.ylabel(\"seconds\")\n        plt.title(f\"Mean vs winsor-mean — {vname}\")\n        plt.legend()\n        pdf.savefig(bbox_inches=\"tight\")\n        plt.close()\n\n    fig = plt.figure(figsize=(8.27, 4))\n    lines = []\n    lines.append(\"Permutation test for difference in means (manual - auto)\")\n    lines.append(f\"implicit_close: diff={diff_imp:.2f}s, p={p_imp:.4f}\")\n    lines.append(f\"skip_double_open: diff={diff_skp:.2f}s, p={p_skp:.4f}\")\n    plt.axis(\"off\")\n    plt.text(0.05, 0.92, \"\\n\".join(lines), va=\"top\", ha=\"left\", fontsize=11, family=\"monospace\")\n    pdf.savefig(fig, bbox_inches=\"tight\")\n    plt.close(fig)\n\nprint(\"Saved:\", os.path.join(OUT_DIR, \"episodes_implicit.csv\"))\nprint(\"Saved:\", os.path.join(OUT_DIR, \"episodes_skip.csv\"))\nprint(\"Saved:\", pdf_path)\nprint(\"Done\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "<ipython-input-2-459148f7aec4>:61: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  ep[\"censored\"] = ep[\"censored\"].fillna(False)\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Saved: ./episodes_implicit.csv\nSaved: ./episodes_skip.csv\nSaved: ./toolwindow_analysis_comparison_with_winsor.pdf\nDone\n"
        }
      ],
      "execution_count": 2
    }
  ]
}